{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [SQL](https://www.kaggle.com/learn/intro-to-sql) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/select-from-where).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nTry writing some **SELECT** statements of your own to explore a large dataset of air pollution measurements.\n\nRun the cell below to set up the feedback system.","metadata":{}},{"cell_type":"code","source":"# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.sql.ex2 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2022-02-28T11:29:08.555244Z","iopub.execute_input":"2022-02-28T11:29:08.555528Z","iopub.status.idle":"2022-02-28T11:29:08.561300Z","shell.execute_reply.started":"2022-02-28T11:29:08.555500Z","shell.execute_reply":"2022-02-28T11:29:08.560661Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"The code cell below fetches the `global_air_quality` table from the `openaq` dataset.  We also preview the first five rows of the table.","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"openaq\" dataset\ndataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)\n\n# Construct a reference to the \"global_air_quality\" table\ntable_ref = dataset_ref.table(\"global_air_quality\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the \"global_air_quality\" table\nresults = client.list_rows(table).to_dataframe()\nnew_res = results[['city','pollutant','unit']]\nnew_res\n","metadata":{"execution":{"iopub.status.busy":"2022-02-28T11:30:12.276152Z","iopub.execute_input":"2022-02-28T11:30:12.276445Z","iopub.status.idle":"2022-02-28T11:30:15.475819Z","shell.execute_reply.started":"2022-02-28T11:30:12.276414Z","shell.execute_reply":"2022-02-28T11:30:15.474871Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"# Exercises\n\n### 1) Units of measurement\n\nWhich countries have reported pollution levels in units of \"ppm\"?  In the code cell below, set `first_query` to an SQL query that pulls the appropriate entries from the `country` column.\n\nIn case it's useful to see an example query, here's some code from the tutorial:\n\n```\nquery = \"\"\"\n        SELECT city\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country = 'US'\n        \"\"\"\n```","metadata":{}},{"cell_type":"code","source":"# Query to select countries with units of \"ppm\"\n\nfirst_query = \"\"\"\n              SELECT country\n              FROM `bigquery-public-data.openaq.global_air_quality`\n              WHERE unit = \"ppm\"\n              \"\"\"\n# Your code goes here\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 10 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nfirst_query_job = client.query(first_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nfirst_results = first_query_job.to_dataframe()\n\n# View top few rows of results\nprint(first_results.head())\n\n# Check your answer\nq_1.check()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T11:06:23.049999Z","iopub.execute_input":"2022-02-28T11:06:23.050276Z","iopub.status.idle":"2022-02-28T11:06:24.097202Z","shell.execute_reply.started":"2022-02-28T11:06:23.050247Z","shell.execute_reply":"2022-02-28T11:06:24.096467Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"#q_1.solution()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T11:04:45.583932Z","iopub.execute_input":"2022-02-28T11:04:45.584238Z","iopub.status.idle":"2022-02-28T11:04:45.588419Z","shell.execute_reply.started":"2022-02-28T11:04:45.584209Z","shell.execute_reply":"2022-02-28T11:04:45.587454Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### 2) High air quality\n\nWhich pollution levels were reported to be exactly 0?  \n- Set `zero_pollution_query` to select **all columns** of the rows where the `value` column is 0.\n- Set `zero_pollution_results` to a pandas DataFrame containing the query results.","metadata":{}},{"cell_type":"code","source":"# Query to select all columns where pollution levels are exactly 0\nzero_pollution_query = \"\"\"\n                       SELECT *\n                       FROM `bigquery-public-data.openaq.global_air_quality`\n                       WHERE value = 0\n                       \"\"\"\n\n# Set up the query\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(zero_pollution_query, job_config=safe_config)\n\n# API request - run the query and return a pandas DataFrame\nzero_pollution_results = query_job.to_dataframe() # Your code goes here\n\nprint(zero_pollution_results.head())\n\n# Check your answer\nq_2.check()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T11:31:26.586105Z","iopub.execute_input":"2022-02-28T11:31:26.586387Z","iopub.status.idle":"2022-02-28T11:31:27.700979Z","shell.execute_reply.started":"2022-02-28T11:31:26.586353Z","shell.execute_reply":"2022-02-28T11:31:27.699859Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"#q_2.solution()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T11:31:31.468855Z","iopub.execute_input":"2022-02-28T11:31:31.469135Z","iopub.status.idle":"2022-02-28T11:31:31.473081Z","shell.execute_reply.started":"2022-02-28T11:31:31.469108Z","shell.execute_reply":"2022-02-28T11:31:31.472113Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"That query wasn't too complicated, and it got the data you want. But these **SELECT** queries don't organizing data in a way that answers the most interesting questions. For that, we'll need the **GROUP BY** command. \n\nIf you know how to use [`groupby()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) in pandas, this is similar. But BigQuery works quickly with far larger datasets.\n\nFortunately, that's next.","metadata":{}},{"cell_type":"markdown","source":"# Keep going\n**[GROUP BY](https://www.kaggle.com/dansbecker/group-by-having-count)** clauses and their extensions give you the power to pull interesting statistics out of data, rather than receiving it in just its raw format.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-sql/discussion) to chat with other learners.*","metadata":{}}]}